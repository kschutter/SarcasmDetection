{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data, dropping nulls and columns that won't help predictions\n",
    "df = pd.read_csv('../data/train-balanced-sarcasm.csv')\n",
    "df.drop(['author','ups','downs','date'], axis=1, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>2016-10-18 21:03:47</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-12-30 17:00:13</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0                                         NC and NH.   \n",
       "1      0  You do know west teams play against west teams...   \n",
       "2      0  They were underdogs earlier today, but since G...   \n",
       "3      0  This meme isn't funny none of the \"new york ni...   \n",
       "4      0                    I could use one of those tools.   \n",
       "\n",
       "            subreddit  score          created_utc  \\\n",
       "0            politics      2  2016-10-16 23:55:23   \n",
       "1                 nba     -4  2016-11-01 00:24:10   \n",
       "2                 nfl      3  2016-09-22 21:45:37   \n",
       "3  BlackPeopleTwitter     -8  2016-10-18 21:03:47   \n",
       "4  MaddenUltimateTeam      6  2016-12-30 17:00:13   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-index our dataframe after dropping nulls\n",
    "df.shape\n",
    "df.index = range(1010773)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train-Test split our data in a 70-30 split, then tokenize the comment and parents comment columns\n",
    "train, test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['comment']), tags=[r.comment]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['comment']), tags=[r.comment]), axis=1)\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['parent_comment']), tags=[r.parent_comment]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['parent_comment']), tags=[r.parent_comment]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 707541/707541 [00:00<00:00, 3606751.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build our vocab\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 707541/707541 [00:00<00:00, 3421757.12it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3502196.27it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3643572.02it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3586413.07it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3759702.29it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3683555.86it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3330421.53it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3666752.39it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3749337.72it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3677011.01it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3430645.38it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3751432.61it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3583836.07it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3578313.44it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3404356.27it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3464892.19it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3613329.59it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3714162.76it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3617941.75it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3680463.10it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3684232.67it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3701363.29it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3317428.38it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3833330.81it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3404336.75it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3514539.55it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3375738.44it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3727959.36it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3776183.31it/s]\n",
      "100%|██████████| 707541/707541 [00:00<00:00, 3260073.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34min 42s, sys: 2min 59s, total: 37min 42s\n",
      "Wall time: 15min 37s\n"
     ]
    }
   ],
   "source": [
    "# Train our doc2vec model in gensim with 30 epochs\n",
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Attempt a logistic regression on our data\n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
